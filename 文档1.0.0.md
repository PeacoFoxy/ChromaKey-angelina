## **项目文档：ChromaKey AI**

### **1. 项目背景与愿景 (Background & Vision)**

1.1. 问题陈述：

在当前的数字内容创作时代，无论是专业主播、远程办公人员还是普通视频爱好者，都面临一个共同的痛点：如何获得一个干净、专业的视频背景。目前的解决方案存在两难困境：

- **物理方案：** 搭建实体绿幕、布置专业灯光。这套流程不仅成本高昂、占用空间，而且极其繁琐，极大地限制了创作的灵活性和自发性。
- **云端方案：** 使用基于云的AI抠图服务。这类服务虽然方便，但其核心缺陷是致命的：**隐私泄露风险**（用户的视频流被上传至第三方服务器）、**高延迟**（网络传输和云端计算耗时）、**网络依赖**（无网络则无法使用）以及持续的订阅费用。

1.2. 我们的愿景：

ChromaKey AI 项目旨在彻底解决这一痛点。我们的愿景是，利用 Snapdragon® X Elite处理器 强大的端侧AI计算能力，打造一款完全在本地设备运行、无需绿幕、零延迟、绝对保护隐私的实时视频背景处理工具。我们不仅仅是在做一个“抠图软件”，我们是在创造一个属于每个人的、智能、安全且高效的个人虚拟演播室。



### **2. 黑客松目标与“完成”标准 (Hackathon Goal & Definition of Done)**



2.1. 核心目标：

在10-12小时的有效开发时间内，完成一个功能稳定、效果惊艳的最小可行产品（MVP），并在最终的5分钟演示 中，完美展示其核心价值，冲击本次黑客松大奖。我们的项目设计将严格对标官方评分标准，尤其是在 “技术实现（40分）”、“应用用例与创新（25分）” 和 “本地处理与隐私（15分）” 这三个高分项上取得优势。

2.2. MVP定义：

我们的MVP必须包含以下核心功能：

- **功能A (必须实现): 实时背景替换。** 程序能够调用摄像头，实时、流畅地将视频中的人物与背景分离，并将背景替换为一张用户指定的静态图片或纯色背景。

- 好的，我们来将 **功能A (必须实现): 实时背景替换** 这一核心任务，分解成一个更详细、可执行的技术步骤清单。这可以作为你们团队在黑客松期间的行动指南。

  ------

  

  ### **功能A：实时背景替换 - 详细技术实现步骤**

  

  这个核心功能的实现，可以拆解为以下 **6个关键任务**。建议你们团队严格按照这个顺序推进，完成一步，再进入下一步。

  **任务1：环境搭建与基础视频流**

  - **目标：** 确保开发环境就绪，并能成功调用摄像头。
  - **步骤：**
    1. 在官方提供的Snapdragon PC上，安装Python和本次项目所需的核心库：`opencv-python`, `onnxruntime`, `numpy`。
    2. 编写一个最基础的Python脚本 (`step1_capture.py`)。
    3. 使用`OpenCV`调用并打开设备的默认摄像头。
    4. 在一个循环中，持续读取摄像头的视频帧。
    5. 使用`cv2.imshow()`在一个窗口中实时显示原始的、未经处理的视频画面。
    6. 确保程序可以通过按键（例如‘q’键）正常退出。
  - **完成标志：** 能够看到一个稳定、流畅的本地摄像头画面。

  **任务2：AI模型选择与加载**

  - **目标：** 找到并成功加载一个用于人像分割的AI模型。
  - **步骤：**
    1. **首要任务：** 访问Qualcomm AI Hub，寻找官方提供的、为Snapdragon优化的、`.onnx`格式的**语义分割 (Semantic Segmentation)** 或 **人像分割 (Portrait Segmentation)** 模型。
    2. **备选方案：** 如果AI Hub上没有合适的，可以在Hugging Face等社区寻找轻量级的、预训练好的ONNX模型。
    3. 编写一个新的脚本 (`step2_load_model.py`)，使用`onnxruntime`库加载下载好的`.onnx`模型文件。
  - **完成标志：** 程序运行后，模型能够被成功加载到内存中，不抛出任何错误。

  **任务3：图像预处理**

  - **目标：** 将摄像头捕捉的画面，转换成AI模型能够接受的格式。
  - **步骤：**
    1. 在`step1_capture.py`的视频循环中，获取到每一帧的图像 (这是一个NumPy数组)。
    2. 查询你下载的ONNX模型的输入要求（通常是固定的图像尺寸，如 256x256）。
    3. 使用`OpenCV`的`cv2.resize()`函数，将视频帧缩放到模型所需的尺寸。
    4. 进行归一化处理，例如将像素值从 [0, 255] 的范围转换到 [0, 1]。
    5. 调整数据维度以匹配模型输入格式（例如，从 HWC 转换为 CHW，并增加Batch维度）。
  - **完成标志：** 在循环的每一步，都能生成一个格式正确、可以送入模型的NumPy数组。

  **任务4：NPU实时推理**

  - **目标：** 在NPU上运行AI模型，获取人像蒙版(Mask)。
  - **步骤：**
    1. 将任务3中预处理好的图像数组，作为输入传递给已加载的`onnxruntime`会话 (session)。
    2. 执行`session.run()`来进行模型推理。这个过程会自动利用Snapdragon NPU进行加速。
    3. 接收模型的输出结果。对于分割模型，这个输出通常是一个代表“蒙版”的二维数组。
  - **完成标志：** 能够稳定地从模型获取到推理结果，且单次推理耗时极短（通常在几十毫秒内），保证实时性。

  **任务5：结果后处理与蒙版应用**

  - **目标：** 将模型输出的原始蒙版，处理成可用于图像合成的工具。
  - **步骤：**
    1. 读取一张你想要用作背景的静态图片，并将其尺寸调整到与原始视频帧相同。
    2. 将任务4中模型输出的原始蒙版，通过`cv2.resize()`恢复到与原始视频帧相同的尺寸。
    3. 对蒙版进行二值化处理，使其成为一个纯黑白图像（例如，人物区域为白色，背景为黑色）。
    4. 利用这个蒙版和它的反向蒙版，分别从原始视频帧中“抠”出人物，以及从背景图中“抠”出需要填充的区域。
  - **完成标志：** 能够生成两张处理过的图像：一张是背景透明的人物像，一张是中间为人像形状的背景图。

  **任务6：图像合成与最终显示**

  - **目标：** 将处理后的人物和背景完美融合，并实时显示。
  - **步骤：**
    1. 使用`OpenCV`的图像加法或位运算，将任务5中生成的两张图像合成为最终的画面。
    2. 将`cv2.imshow()`的目标从原始视频帧，改为这个合成后的最终画面。
  - **完成标志：** 屏幕上显示的不再是原始摄像头画面，而是你实时置身于一个全新静态背景中的画面，且流畅无卡顿。

2.3. “完成”的标准 (Definition of Done):

当以下所有条件都满足时，我们的黑客松项目即视为“完成”：

1. **[ ] 功能稳定:** MVP的核心功能A能够稳定运行超过5分钟，无明显卡顿或崩溃。
2. **[ ] 打包成功:** 整个Python项目已成功打包成一个独立的 **`.EXE` 可执行文件**，评委可以轻松运行。
3. **[ ] 文档完备:** 项目的GitHub仓库中包含一个格式规范的 `README.md` 文件，内容涵盖应用描述、团队成员信息、详细的安装和使用说明。
4. **[ ] 开源合规:** 项目已选择并包含一个开源许可证（例如 MIT License）。
5. **[ ] 演示就绪:** 团队已准备好5分钟的演示文稿，并进行了至少两次完整排练。



### **3. 技术选型与架构 (Tech Stack & Architecture)**



**3.1. 开发语言：**

- **Python:** 官方提供Python示例应用，且AI生态系统最成熟，是快速原型开发的首选。

**3.2. 核心技术栈：**

- **ONNX Runtime:** 用于加载`.onnx`格式的AI模型，并调用Snapdragon NPU进行硬件加速推理，是发挥硬件性能的关键。
- **OpenCV (`opencv-python`):** 负责所有视频流处理，包括摄像头捕获、图像预处理、画面合成与显示。
- **NumPy:** 用于进行高效的图像数组运算，是AI处理的基石。
- **PyInstaller:** 用于将我们的Python项目最终打包成`.EXE`文件。
- 使用uv和虚拟环境。

3.3. 项目架构：

我们将参考官方NPU Pose Detection示例应用 的处理流程，构建我们的数据流水线：

1. **视频捕获 (OpenCV):** 实时读取摄像头视频帧。
2. **图像预处理 (OpenCV, NumPy):** 将视频帧调整为AI模型所需的尺寸和格式。
3. **NPU推理 (ONNX Runtime):** 将处理好的图像送入在NPU上运行的**语义分割模型**，计算出人物区域的蒙版(Mask)。
4. **图像后处理 (OpenCV, NumPy):** 利用蒙版将人物从原图中“抠”出，并与新的背景图片合成。
5. **渲染显示 (OpenCV):** 将最终合成的画面实时显示在屏幕上。

------